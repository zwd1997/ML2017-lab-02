{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pylab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_error(b, m, x, y, c=0.9):\n",
    "    totalError = 0\n",
    "    N = len(y)\n",
    "    x.shape = (N, 14)\n",
    "    totalError += (m.T.dot(m)) * 0.5\n",
    "    temp2 = 0\n",
    "    for i in range(N):\n",
    "        temp = (1 - y[i] * (x[i].dot(m) + b))\n",
    "        if (temp > 0):\n",
    "            pass\n",
    "        else:\n",
    "            temp = 0\n",
    "        totalError += c * temp\n",
    "    totalError/=float(N)\n",
    "    #totalError=totalError.tolist()\n",
    "    return totalError[0,0]\n",
    "\n",
    "\n",
    "def optimizer(x, y, x_test, y_test, starting_b, starting_m, learning_rate, num_iter, c=0.9):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    m.shape = (14, 1)\n",
    "    error_list1 = []\n",
    "    error_list2 = []\n",
    "    m_min = 0\n",
    "    b_min = 0\n",
    "    error_min = 1\n",
    "    # br, mr = compute_gradient(starting_b, starting_m, x_test, y_test, learning_rate,c)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        if (i == 0):\n",
    "            b, m = compute_gradient_all(b, m, x, y, x_test, y_test, learning_rate, c)\n",
    "        else:\n",
    "            b, m = compute_gradient(b, m, x, y, learning_rate, c)\n",
    "        if (i % 10 == 0):\n",
    "            temp = compute_error(b, m, x, y, c)\n",
    "            print('iter {0}:error={1}'.format(i, temp))\n",
    "        temp = compute_error(b, m, x, y, c)\n",
    "        error_list1.append(temp)\n",
    "        if (temp < error_min):\n",
    "            error_min = temp\n",
    "            b_min = b\n",
    "            m_min = m\n",
    "        temp2 = compute_error(b, m, x_test, y_test, c)\n",
    "        error_list2.append(temp2)\n",
    "    return [b_min, m_min, error_list1, error_list2]\n",
    "\n",
    "\n",
    "def compute_gradient(b_current, m_current, x, y, learning_rate, c=0.9):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    gw = 0\n",
    "    gb = 0\n",
    "    n = len(y)\n",
    "    N = float(n)\n",
    "    i = random.randint(0, n - 1)\n",
    "    y.shape = (n, 1)\n",
    "    m_current.shape = (14, 1)\n",
    "    if ((1 - y[i] * (x[i, :].dot(m_current)) >= 0)):\n",
    "        gw = -y[i] * x[i, :]\n",
    "        gb = -y[i]\n",
    "        m_gradient = c * (gw.T)\n",
    "    else:\n",
    "        gw = 0\n",
    "        gb = 0\n",
    "        m_gradient = m_current\n",
    "\n",
    "    b_gradient = c * gb\n",
    "\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return [new_b, new_m]\n",
    "\n",
    "\n",
    "def compute_gradient_all(b_current, m_current, x_train, y_train, x_test, y_test, learning_rate, c=0.9):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    gw = 0\n",
    "    gb = 0\n",
    "    nt = len(y_train)\n",
    "    nn = len(y_test)\n",
    "    x_train.shape = (nt, 14)\n",
    "    x_test.shape = (nn, 14)\n",
    "    y_train.shape = (nt, 1)\n",
    "    y_test.shape = (nn, 1)\n",
    "    m_current.shape = (14, 1)\n",
    "    m_gradient = 0\n",
    "    # m_gradient.shape = (14,1)\n",
    "    for i in range(nt):\n",
    "        if ((1 - y_train[i] * (x_train[i, :].dot(m_current)) >= 0)):\n",
    "            gw = -y_train[i] * x_train[i, :]\n",
    "            gb = -y_train[i]\n",
    "            m_gradient += c * (gw.T)\n",
    "        else:\n",
    "            gw = 0\n",
    "            gb = 0\n",
    "            m_gradient += 0\n",
    "        b_gradient += c * gb\n",
    "    for i in range(nn):\n",
    "        if ((1 - y_test[i] * (x_test[i, :].dot(m_current)) >= 0)):\n",
    "            gw = -y_test[i] * x_test[i, :]\n",
    "            gb = -y_test[i]\n",
    "            m_gradient += c * (gw.T)\n",
    "        else:\n",
    "            gw = 0\n",
    "            gb = 0\n",
    "            m_gradient += 0\n",
    "        b_gradient += c * gb\n",
    "\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return [new_b, new_m]\n",
    "\n",
    "\n",
    "def plot_data(error, error2):\n",
    "    n = range(len(error))\n",
    "    #error=error.tolist()\n",
    "    #error2=error2.tolist()\n",
    "    pylab.plot(n, error, label='train')\n",
    "    pylab.plot(n, error2, label='test')\n",
    "    plt.legend()\n",
    "    pylab.show()\n",
    "\n",
    "\n",
    "def Linear_regression():\n",
    "    # data = np.loadtxt('data.csv',delimiter=',')\n",
    "    data = load_svmlight_file('australian_scale.txt')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data[0], data[1], test_size=0.33, random_state=55)\n",
    "    y_t = len(y_train)\n",
    "    y_e = len(y_test)\n",
    "    x_train = x_train.todense()\n",
    "    x_test = x_test.todense()\n",
    "    y_train.reshape((y_t, 1))\n",
    "    y_test.reshape((y_e, 1))\n",
    "    learning_rate = 0.008\n",
    "    init_b = 0.0\n",
    "    init_m = np.zeros(14)\n",
    "    num_iter = 1000\n",
    "    error = 0\n",
    "    error2 = 0\n",
    "    c = 0.9\n",
    "\n",
    "    [b, m, error, error2] = optimizer(x_train, y_train, x_test, y_test, init_b, init_m, learning_rate, num_iter, c)\n",
    "\n",
    "    print('final formula parmaters:\\n b = {1}\\n m={2}\\n error of end = {3} \\n'.format(num_iter, b, m,compute_error(b, m, x_train,y_train, c)))\n",
    "\n",
    "    plot_data(error, error2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Linear_regression()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
